{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb6aba4",
   "metadata": {},
   "source": [
    "# Notebook 2 â€” PSO-Tuned LightGBM Training\n",
    "\n",
    "This notebook consumes the balanced parquet generated in Notebook 1 and performs PSO-guided hyperparameter tuning for LightGBM. The resulting model + validation metrics are stored under `artifacts/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff226d7",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Import configuration + helper modules.\n",
    "2. Load the processed dataset and create deterministic train/val/test splits.\n",
    "3. Launch PSO search to optimize key LightGBM hyperparameters.\n",
    "4. Train the final model on train+val data and log validation performance.\n",
    "5. Persist the model (`artifacts/models/lightgbm_pso.pkl`) and metrics JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1249ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import DEFAULT_CONFIG_PATH, load_config\n",
    "\n",
    "config = load_config(DEFAULT_CONFIG_PATH)\n",
    "processed_path = Path(config.data.processed_file)\n",
    "if not processed_path.exists():\n",
    "    raise FileNotFoundError(f\"Processed dataset not found at {processed_path}. Run Notebook 1 first.\")\n",
    "\n",
    "print(processed_path)\n",
    "df = pd.read_parquet(processed_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4860864",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = config.data.label_column\n",
    "X = df.drop(columns=[label_col])\n",
    "y = df[label_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=config.training.test_size,\n",
    "    stratify=y,\n",
    "    random_state=config.training.random_state,\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=config.training.val_size,\n",
    "    stratify=y_train,\n",
    "    random_state=config.training.random_state,\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914fdb9",
   "metadata": {},
   "source": [
    "### Run PSO search + final training\n",
    "\n",
    "Set `RUN_TRAINING=True` to launch the PSO loop. Training can take several minutes depending on the number of particles/iterations in the YAML config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.pso_lightgbm import PSOLightGBMTuner\n",
    "\n",
    "RUN_TRAINING = False\n",
    "best_params = None\n",
    "model = None\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    tuner = PSOLightGBMTuner(config)\n",
    "    best_params = tuner.fit(X_train, y_train)\n",
    "    model = tuner.train_best_model(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "    print(\"Best params:\\n\", best_params)\n",
    "else:\n",
    "    print(\"Skipping PSO training. Set RUN_TRAINING=True to execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    val_preds = model.predict(X_val)\n",
    "    report = classification_report(y_val, val_preds, output_dict=True)\n",
    "    print(\"Validation macro F1:\", report[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "    model_path = config.paths.models_path / \"lightgbm_pso.pkl\"\n",
    "    metrics_path = config.paths.metrics_path / \"validation_report.json\"\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(model, model_path)\n",
    "    Path(metrics_path).write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "else:\n",
    "    \n",
    "    print(\"Model not trained in this session.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160808a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
