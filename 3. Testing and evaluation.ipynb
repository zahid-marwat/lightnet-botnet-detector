{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0815aff1",
   "metadata": {},
   "source": [
    "# Notebook 3 â€” Testing & Evaluation\n",
    "\n",
    "Loads the trained LightGBM model and produces final test metrics, including confusion matrix and per-class scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683e35e",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "1. Reload the YAML config and processed parquet.\n",
    "2. Split data identically to the training notebook to obtain the test partition.\n",
    "3. Load the saved `lightgbm_pso.pkl` model.\n",
    "4. Compute classification report, confusion matrix, and visualize results.\n",
    "5. Persist test metrics to `artifacts/metrics/test_report.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3998436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import DEFAULT_CONFIG_PATH, load_config\n",
    "\n",
    "config = load_config(DEFAULT_CONFIG_PATH)\n",
    "processed_path = Path(config.data.processed_file)\n",
    "model_path = config.paths.models_path / \"lightgbm_pso.pkl\"\n",
    "\n",
    "if not processed_path.exists() or not model_path.exists():\n",
    "    raise FileNotFoundError(\"Ensure processed data and trained model exist before running evaluation.\")\n",
    "\n",
    "df = pd.read_parquet(processed_path)\n",
    "label_col = config.data.label_column\n",
    "X = df.drop(columns=[label_col])\n",
    "y = df[label_col]\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=config.training.test_size,\n",
    "    stratify=y,\n",
    "    random_state=config.training.random_state,\n",
    ")\n",
    "\n",
    "test_sample = X_test.iloc[:5]\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c960005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(model_path)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds, output_dict=True)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Test macro F1:\", report[\"macro avg\"][\"f1-score\"])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23df12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"classification_report\": report,\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "metrics_path = config.paths.metrics_path / \"test_report.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Saved metrics to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85246b61",
   "metadata": {},
   "source": [
    "ðŸŽ¯ **Outcome**: Test metrics are now logged under `artifacts/metrics/test_report.json`. Share plots/confusion matrix screenshots in your final report."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
